{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import common packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "import errno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import findspark and import&init spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--master local[4] pyspark-shell\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "\n",
    "\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/ser/Dev/Spark/spark-2.1.0-bin-hadoop2.7\"\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/home/ser/Dev/Python/2/anaconda2/bin/python\"\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = \"--master local[4] pyspark-shell\"\n",
    "#os.environ['PYSPARK_SUBMIT_ARGS'] = \"--master yarn \\\n",
    "                                     #--deploy-mode cluster \\\n",
    "                                     #--conf \\\"spark.yarn.am.port\\\"=8025\\\n",
    "                                     #pyspark-shell\"\n",
    "print os.environ['PYSPARK_SUBMIT_ARGS']\n",
    "#os.environ['HADOOP_CONF_DIR'] = \"/home/ser/Dev/Hadoop/hadoop-2.7.3/etc/hadoop\"\n",
    "findspark.init()\n",
    "\n",
    "#import numpy as np\n",
    "#import sep\n",
    "#from operator import add\n",
    "\n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext, Row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import task-oriented packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import astromatic_wrapper as aw\n",
    "from astropy.io import fits\n",
    "#import pydoop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants (in future go to config file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exec_mode = 'test'\n",
    "wrk_path = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0, '/home/ser/Dev/astro_engine/code')\n",
    "from astro_utils import AEDirsTreeConfigurer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'catalogs': '/home/ser/Dev/astro_engine/spark_pipeline/spark_pipeline_test_1/catalogs',\n",
       " 'config': '/home/ser/Dev/astro_engine/spark_pipeline/spark_pipeline_test_1/config',\n",
       " 'images': '/home/ser/Dev/astro_engine/spark_pipeline/spark_pipeline_test_1/images',\n",
       " 'logs': '/home/ser/Dev/astro_engine/spark_pipeline/spark_pipeline_test_1/logs',\n",
       " 'stacks': '/home/ser/Dev/astro_engine/spark_pipeline/spark_pipeline_test_1/stacks',\n",
       " 'temp': '/home/ser/Dev/astro_engine/spark_pipeline/spark_pipeline_test_1/temp'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = AEDirsTreeConfigurer(False, images_path='images')\n",
    "cfg.build_dirs_tree()\n",
    "cfg.new_log_dir()\n",
    "cfg.get_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AEConfig:\n",
    "    def __init__(self):\n",
    "        self._scamp_required_sex_params = ['NUMBER', 'EXT_NUMBER', 'XWIN_IMAGE', 'YWIN_IMAGE', \n",
    "                                           'AWIN_IMAGE', 'BWIN_IMAGE', 'ERRAWIN_IMAGE','ERRBWIN_IMAGE', \n",
    "                                           'ERRTHETAWIN_IMAGE', 'ERRA_WORLD', 'ERRB_WORLD','ERRTHETA_WORLD', \n",
    "                                           'X_WORLD', 'Y_WORLD', 'XWIN_WORLD', 'YWIN_WORLD', 'FLUX_AUTO', \n",
    "                                           'FLUX_MAX', 'MAG_AUTO', 'FLUXERR_AUTO', \n",
    "                                           # flags not supported yet (need Weightwatcher)\n",
    "                                           #'IMAFLAGS_ISO', 'FLAGS_WEIGHT',\n",
    "                                           'FLAGS', 'FLUX_RADIUS', 'ELONGATION']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark code separately yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_1(input_item, broadcast_fits):\n",
    "    from astro_utils import AEDirsTreeConfigurer\n",
    "    cfg = AEDirsTreeConfigurer(False, images_path='images' + str(input_item[0][-1]))\n",
    "    cfg.build_dirs_tree()\n",
    "    cfg.new_log_dir()\n",
    "    file_name = input_item[0].replace('file:', '')\n",
    "    catalog_name = os.path.join(cfg.get_paths()['catalogs'], os.path.basename(file_name.replace('.fit', '.cat')))\n",
    "    sex_kwargs_1 = {'code': 'SExtractor'}\n",
    "    sex_kwargs_1['config_file'] = os.path.join(cfg.get_paths()['config'], 'default.sex')\n",
    "    sex_kwargs_1['config'] = {'CATALOG_NAME': catalog_name}\n",
    "    sex_kwargs_1['config']['CATALOG_TYPE'] = 'FITS_LDAC'\n",
    "    sex_kwargs_1['config']['FILTER'] = 'N'\n",
    "    sex_kwargs_1['temp_path'] = cfg.get_paths()['temp']\n",
    "    sex_kwargs_1['params'] = ['NUMBER', 'EXT_NUMBER', 'XWIN_IMAGE', 'YWIN_IMAGE', 'AWIN_IMAGE', 'BWIN_IMAGE',\n",
    "                              'ERRAWIN_IMAGE','ERRBWIN_IMAGE', 'ERRTHETAWIN_IMAGE', 'ERRA_WORLD', 'ERRB_WORLD', \n",
    "                              'ERRTHETA_WORLD', 'X_WORLD', 'Y_WORLD', 'XWIN_WORLD', 'YWIN_WORLD', \n",
    "                              'FLUX_AUTO', 'FLUX_MAX', 'MAG_AUTO', 'FLUXERR_AUTO', \n",
    "                              'FLAGS', 'FLUX_RADIUS', 'ELONGATION']\n",
    "    sextractor = aw.api.Astromatic(**sex_kwargs_1)\n",
    "    sextractor.run(file_name)\n",
    "    #with open(catalog_name, \"r\") as catalog:\n",
    "        #output_item = ('file:' + catalog_name, catalog)\n",
    "    return catalog_name + str(broadcast_fits.value[0].header['BITPIX'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_2(input_item):\n",
    "    file_name = input_item[0]\n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_3(input_item):\n",
    "    file_name = os.path.basename(input_item[0])\n",
    "    tmp_file_name = os.path.join(cfg.get_paths()['temp'], file_name)\n",
    "    catalog_name = os.path.join(cfg.get_paths()['catalogs'], file_name.replace('.fit', '.cat'))\n",
    "    with open(tmp_file_name, \"w+\") as fits_file:\n",
    "        fits_file.write(input_item[1])\n",
    "    sex_kwargs_1 = {'code': 'SExtractor'}\n",
    "    sex_kwargs_1['config_file'] = os.path.join(cfg.get_paths()['config'], 'default.sex')\n",
    "    sex_kwargs_1['config'] = {'CATALOG_NAME': catalog_name}\n",
    "    sex_kwargs_1['config']['CATALOG_TYPE'] = 'FITS_LDAC'\n",
    "    sex_kwargs_1['config']['FILTER'] = 'N'\n",
    "    sex_kwargs_1['temp_path'] = cfg.get_paths()['temp']\n",
    "    sex_kwargs_1['params'] = ['NUMBER', 'EXT_NUMBER', 'XWIN_IMAGE', 'YWIN_IMAGE', 'AWIN_IMAGE', 'BWIN_IMAGE',\n",
    "                              'ERRAWIN_IMAGE','ERRBWIN_IMAGE', 'ERRTHETAWIN_IMAGE', 'ERRA_WORLD', 'ERRB_WORLD', \n",
    "                              'ERRTHETA_WORLD', 'X_WORLD', 'Y_WORLD', 'XWIN_WORLD', 'YWIN_WORLD', \n",
    "                              'FLUX_AUTO', 'FLUX_MAX', 'MAG_AUTO', 'FLUXERR_AUTO', \n",
    "                              'FLAGS', 'FLUX_RADIUS', 'ELONGATION']\n",
    "    sextractor = aw.api.Astromatic(**sex_kwargs_1)\n",
    "    sextractor.run(tmp_file_name)\n",
    "    with open(catalog_name, \"r\") as catalog:\n",
    "        output_item = ('file:' + catalog_name, catalog)\n",
    "    return output_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rt_1(input_i):\n",
    "    return [a[0] for a in input_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: check header_edit_script!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from pyspark import SparkFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "org.apache.spark.api.java.JavaPairRDD@79d52e70\n",
      "11 32 35.230\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    sc = SparkContext(appName=\"SourceExtractor\")\n",
    "    sc.addPyFile('/home/ser/Dev/astro_engine/code/astro_utils.py')\n",
    "    sc.addPyFile('/home/ser/Dev/astro_engine/code/fits_utils.py')\n",
    "    bd_fits = fits.open('im_1.fit')\n",
    "    broadcast_fits = sc.broadcast(bd_fits)\n",
    "    \n",
    "    files = sc.binaryFiles(cfg.get_paths()['images'])\n",
    "    #files = sc.binaryFiles(\"hdfs://localhost:9000/ser/images/images\")\n",
    "    print files\n",
    "    print broadcast_fits.value[0].header['RA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = files.filter(lambda x: x[0].endswith('.fit'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'file:/home/ser/Dev/astro_engine/spark_pipeline/spark_pipeline_test_1/images/GRB130427_R60_001_001.fit',\n",
       " u'file:/home/ser/Dev/astro_engine/spark_pipeline/spark_pipeline_test_1/images/GRB130427_R60_001_003.fit',\n",
       " u'file:/home/ser/Dev/astro_engine/spark_pipeline/spark_pipeline_test_1/images/GRB130427_R60_001_006.fit',\n",
       " u'file:/home/ser/Dev/astro_engine/spark_pipeline/spark_pipeline_test_1/images/GRB130427_R60_001_004.fit',\n",
       " u'file:/home/ser/Dev/astro_engine/spark_pipeline/spark_pipeline_test_1/images/GRB130427_R60_001_005.fit',\n",
       " u'file:/home/ser/Dev/astro_engine/spark_pipeline/spark_pipeline_test_1/images/GRB130427_R60_001_002.fit']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print files.map(extract).reduce(join_cats)\n",
    "#files.map(partial(extract_1, broadcast_fits=broadcast_fits)).map(lambda x: [x]).reduce(lambda a, b: a + b)\n",
    "files.mapPartitions(rt_1).map(lambda x : [x]).reduce(lambda a, b: a + b)\n",
    "#catalogs = files.map(extract_3).collect()\n",
    "#len(catalogs)\n",
    "#catalogs.map(lambda x: [x]).reduce(lambda a, b: a + b)\n",
    "#catalogs.saveAsSequenceFile(cfg.get_paths()['catalogs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'file:/home/ser/Dev/Notebooks/spark_pipeline_1/catalogs/GRB130427_R60_001_001.cat',\n",
       " <closed file '<uninitialized file>', mode '<uninitialized file>' at 0x7f573ba3e6f0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#catalogs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
